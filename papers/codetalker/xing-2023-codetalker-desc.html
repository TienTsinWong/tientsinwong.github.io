<p>
<table border=0><tr><td width=300 height=80 align=right valign=top>

  <a href="./papers/codetalker/codetalker.html">
  <img width=300 src="papers/codetalker/images/icon.gif" border=0></a><br>
 

</td><td width=20>
</td><td align=left valign=top  width=600><font face="Verdana" size="2">

  <font size=+0 face="Arial,Helvetica"><b> 
   CodeTalker: Speech-Driven 3D Facial Animation</b>
   <i><b> (CVPR 2023)</b></i></font><br> 
  <p>

While speech-driven 3D facial animation has been heavily studied, there remains
a gap to achieving expressive and dramatic animation, due to the highly ill-posed
nature and scarcity of audiovisual data.  The unique contribution here is on
minimizing the over-smoothed facial expression using a learned discrete
motion prior, which means more dramatic and expressive facial motions with
more accurate lip movements can be achieved.  Such method is not only useful in virtual reality,
games and film productions, but also is beneficial to general non-professional users
without much animation skill.

<br>
<b>
[<a href="./papers/codetalker/codetalker.html">more</a>]
[<a href="https://doubiiu.github.io/projects/codetalker/">more 2</a>]
[<a href="./papers/codetalker/codetalker.pdf">paper</a>]
[<a href="./papers/codetalker/codetalker.mp4">video</a>]
[<a href="https://github.com/Doubiiu/CodeTalker">code</a>]
</td></tr></table>
<p><br>