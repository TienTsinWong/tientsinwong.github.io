<p>
<table border=0><tr><td width=300 height=80 align=right valign=top>

  <a href="./papers/deepcvdvideo/deepcvdvideo.html">
  <img src="papers/deepcvdvideo/img/icon.png" border=0></a><br>
 

</td><td width=20>
</td><td align=left valign=top  width=600><font face="Verdana" size="2">

  <font size=+0 face="Arial,Helvetica"><b> 
  Color-Consistent and Temporal-Coherent Colorblind-Shareable Videos </b>
  <i><b> (SIGGRAPH Asia 2019)</b></i></font><br> 
  <p>

Due to the local nature of CNN models, it is hard to ensure the recoloring is
consistent over the whole image. To solve this problem in our synthesis of
colorblind-shareable videos, we propose to utilize deep learning in
indirectly generating parameters of a polynomial color model. This
guarantees the recoloring is globally applied to the whole image, while
ensuring temporal coherent.

<br>

<b>
[<a href="./papers/deepcvdvideo/deepcvdvideo.html">more</a>]
[<a href="./papers/deepcvdvideo/deepcvdvideo.pdf">paper</a>]
</td></tr></table>
<p><br>