<p>
<table border=0><tr><td width=300 height=80 align=right valign=top>

  <a href="./papers/embedframe/embedframe.html">
  <img src="./papers/embedframe/img/icon.gif"  border=0></a><br>
 

</td><td width=20>
</td><td align=left valign=top  width=600><font face="Verdana" size="2">

  <font size=+0 face="Arial,Helvetica"><b> 
  Video Snapshot</b> (a real live photo)
  <i><b> (IEEE TPAMI 2021)</b></i></font><br> 
  <p>

While iPhone keeps a short video for each "live photo", we propose a method to
embed a short video into a single frame, in other words, a real live photo. We employ
the InvertibleX Model to first encode the neighboring frames into a
single visualizable frame. Whenever the video is needed, a decoding subnetwork
can be used to expand (restore) it.


<br>

<b>
[<a href="./papers/embedframe/embedframe.html">more</a>]
[<a href="https://youtu.be/H5UA5jH4BaQ">youtube</a>]
[<a href="./papers/embedframe/embedframe.pdf"-->paper</a>]
[<a href="https://github.com/chuchienshu/Video-Snapshot">code</a>]
</td></tr></table>
<p><br>